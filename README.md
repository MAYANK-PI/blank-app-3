ğŸ–¼ï¸ Image Segmentation + Caption Generation (U-Net + CNN-LSTM)
ğŸ“Œ Overview

This project combines Image Segmentation (using a U-Net model) and Image Captioning (using a CNN-LSTM model) to both segment and describe images automatically.

The segmentation model highlights different regions in the image (e.g., airplane, person, sky).

The captioning model generates natural-language descriptions based on image features.

The app is deployed using Streamlit, with all data and code hosted on GitHub.

âš™ï¸ Features

âœ… Automatic detection of uploaded images from the images/ folder
âœ… U-Net based segmentation with colorized class masks
âœ… CNN-LSTM based caption generation
âœ… Side-by-side display of:

Original image

Predicted segmentation mask

Mask index map

(Optional) Ground-truth segmentation mask

ğŸ§  Model Architecture
ğŸŸ¢ Segmentation (U-Net)

Encoder: 3 levels of convolution + max-pooling

Decoder: transpose convolution + skip connections

Output: pixel-wise segmentation mask with color coding

ğŸ”µ Captioning (CNN-LSTM)

Encoder: InceptionV3 pretrained on ImageNet

Decoder: LSTM + embedding + dense layers

Output: descriptive text caption
